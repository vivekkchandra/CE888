{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Exercise2_DogvsCat_CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekkchandra/CE888/blob/master/Exercise2_DogvsCat_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjuK7BJ2gwH8",
        "colab_type": "text"
      },
      "source": [
        "**Dogs vs. Cats**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cChBJkLOg06O",
        "colab_type": "text"
      },
      "source": [
        "In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat. This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUTn15ieqYa3",
        "colab_type": "code",
        "outputId": "852d61fe-6301-44fe-8e16-52a0c6fc8eda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.38.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46GGI_VEgusc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"vivekmenas\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"af34b8f238b8c6c40b2524733b04119e\" # key from the json file\n",
        "!kaggle competitions download -c dogs-vs-cats # api copied from kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju7sZ9M_hfqJ",
        "colab_type": "code",
        "outputId": "b303615c-160b-470b-b9cd-16cd0437fa6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Upload data\n",
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"/content/train.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B95KXgsThk6s",
        "colab_type": "code",
        "outputId": "aead15b6-3d99-418d-a0d2-5d47b1bd29d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_dir_list = os.listdir('/content/train')\n",
        "#print(data_dir_list)\n",
        "\n",
        "path, dirs, files = next(os.walk(\"/content/train\"))\n",
        "file_count = len(files)\n",
        "print(file_count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOAIEEAEhnqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_dataset_dir = '/content/train'\n",
        "base_dir = '/content/cats_and_dogs_small2'\n",
        "os.mkdir(base_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aox0FKzVhsRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creates the sub folders\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.mkdir(test_dir)\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')\n",
        "os.mkdir(train_cats_dir)\n",
        "\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
        "os.mkdir(train_dogs_dir)\n",
        "\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
        "os.mkdir(validation_cats_dir)\n",
        "\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
        "os.mkdir(validation_dogs_dir)\n",
        "\n",
        "test_cats_dir = os.path.join(test_dir, 'cats')\n",
        "os.mkdir(test_cats_dir)\n",
        "\n",
        "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
        "os.mkdir(test_dogs_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3s4HOxohzn6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_cats_dir, fname)\n",
        "    #print(src,dst)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_cats_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "    \n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(train_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(validation_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)\n",
        "\n",
        "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
        "for fname in fnames:\n",
        "    src = os.path.join(original_dataset_dir, fname)\n",
        "    dst = os.path.join(test_dogs_dir, fname)\n",
        "    shutil.copyfile(src, dst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We9GOGath2GD",
        "colab_type": "code",
        "outputId": "90dfc815-c68d-41a1-8d75-dc88c2ae8d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
        "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
        "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
        "\n",
        "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
        "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
        "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training cat images: 1000\n",
            "total training dog images: 1000\n",
            "total validation cat images: 500\n",
            "total validation dog images: 500\n",
            "total test cat images: 500\n",
            "total test dog images: 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M25THDhykaeb",
        "colab_type": "code",
        "outputId": "80e51980-d153-4bb9-89cd-4c7fbf5415ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,453,121\n",
            "Trainable params: 3,453,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA60BYXMkfJ9",
        "colab_type": "code",
        "outputId": "86cdaa58-fd75-40a1-dfc2-dbac94424301",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy', \n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHBwX0A3kios",
        "colab_type": "text"
      },
      "source": [
        "**Using ImageDataGenerator to read images from directories**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9zP_wpdkjsN",
        "colab_type": "text"
      },
      "source": [
        "As you know by now, data should be formatted into appropriately preprocessed floatingpoint tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n",
        "\n",
        "*   Read the picture files.\n",
        "*   Decode the JPEG content to RGB grids of pixels.\n",
        "*   Convert these into floating-point tensors.\n",
        "*   Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n",
        "\n",
        "\n",
        "It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class ImageDataGenerator,which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdlOGiBvk2Nf",
        "colab_type": "code",
        "outputId": "65ff6268-3e8b-49c9-d54a-bcecbb3117b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150), \n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=20,\n",
        "                                                        class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qoMrSWIk_8D",
        "colab_type": "text"
      },
      "source": [
        "Let’s fit the model to the data using the generator. You do so using the fit_generator method, the equivalent of fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely,like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring anepoch over. This is the role of the steps_per_epoch argument: after having drawn steps_per_epoch batches from the generator—that is, after having run for steps_per_epoch gradient descent steps—the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples.\n",
        "\n",
        "When using fit_generator, you can pass a validation_data argument, much as with the fit method. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jD92PkwlAdx",
        "colab_type": "code",
        "outputId": "2362c193-7d1b-4556-be0b-e386a5557e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=30,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/30\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "100/100 [==============================] - 97s 966ms/step - loss: 0.6861 - acc: 0.5430 - val_loss: 0.6614 - val_acc: 0.5750\n",
            "Epoch 2/30\n",
            "100/100 [==============================] - 95s 946ms/step - loss: 0.6599 - acc: 0.6110 - val_loss: 0.6303 - val_acc: 0.6550\n",
            "Epoch 3/30\n",
            " 96/100 [===========================>..] - ETA: 3s - loss: 0.6224 - acc: 0.6448"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZEvWvcVlslp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('cats_and_dogs_small_1.h5')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtSMaV45lusT",
        "colab_type": "text"
      },
      "source": [
        "**Convolutional Networks with Dropout**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4SNeFU0lvrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-df-vVvKl35p",
        "colab_type": "text"
      },
      "source": [
        "Instructions for updating:\n",
        "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo1nOIYqlxxg",
        "colab_type": "code",
        "outputId": "a0e41201-d340-4b19-ef54-420b1bba4a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    target_size=(150, 150),\n",
        "                                                    batch_size=32,\n",
        "                                                    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(validation_dir,\n",
        "                                                        target_size=(150, 150),\n",
        "                                                        batch_size=32,\n",
        "                                                        class_mode='binary')\n",
        "\n",
        "history = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=100,\n",
        "                              epochs=20,\n",
        "                              validation_data=validation_generator,\n",
        "                              validation_steps=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n",
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 184s 2s/step - loss: 0.6933 - acc: 0.5144 - val_loss: 0.6899 - val_acc: 0.5298\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.6828 - acc: 0.5487 - val_loss: 0.6661 - val_acc: 0.6044\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.6685 - acc: 0.5806 - val_loss: 0.6513 - val_acc: 0.6174\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.6602 - acc: 0.5959 - val_loss: 0.6425 - val_acc: 0.6282\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 179s 2s/step - loss: 0.6442 - acc: 0.6325 - val_loss: 0.6359 - val_acc: 0.6155\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 183s 2s/step - loss: 0.6379 - acc: 0.6384 - val_loss: 0.6419 - val_acc: 0.6282\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.6157 - acc: 0.6566 - val_loss: 0.5810 - val_acc: 0.7005\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 183s 2s/step - loss: 0.5976 - acc: 0.6778 - val_loss: 0.6403 - val_acc: 0.6057\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.6028 - acc: 0.6753 - val_loss: 0.7463 - val_acc: 0.5754\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 181s 2s/step - loss: 0.5978 - acc: 0.6856 - val_loss: 0.5548 - val_acc: 0.7195\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.5853 - acc: 0.6831 - val_loss: 0.5316 - val_acc: 0.7274\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.5747 - acc: 0.7031 - val_loss: 0.5351 - val_acc: 0.7284\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.5646 - acc: 0.7025 - val_loss: 0.5385 - val_acc: 0.7307\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.5558 - acc: 0.7191 - val_loss: 0.5435 - val_acc: 0.7214\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 180s 2s/step - loss: 0.5573 - acc: 0.7106 - val_loss: 0.5276 - val_acc: 0.7429\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 179s 2s/step - loss: 0.5516 - acc: 0.7159 - val_loss: 0.5082 - val_acc: 0.7494\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 179s 2s/step - loss: 0.5529 - acc: 0.7116 - val_loss: 0.5351 - val_acc: 0.7291\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 182s 2s/step - loss: 0.5456 - acc: 0.7291 - val_loss: 0.5587 - val_acc: 0.6997\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 181s 2s/step - loss: 0.5391 - acc: 0.7222 - val_loss: 0.5782 - val_acc: 0.6948\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 181s 2s/step - loss: 0.5396 - acc: 0.7237 - val_loss: 0.5051 - val_acc: 0.7506\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
